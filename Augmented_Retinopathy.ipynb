{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmented-Retinopathy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MittalNeha/retinopathy-kaggle/blob/master/Augmented_Retinopathy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKIS6iSG2DVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ca82703-db36-4aec-e4f9-c788b6e98163"
      },
      "source": [
        "!curl -H \"Authorization: Bearer ya29.GltWB-PNoWU-1x8DSgBlljjfkMH_iFQuWH4hpDApfsawaeuQ0YB_u6qMk5DprcPbgWUkGU4TEK70ViF2-fq4OvRxlrqY9RkMJIclgjIr2RXjhRnfJviOSPlSTBY-\" https://www.googleapis.com/drive/v3/files/1_2vRmwiJTKwA7eY0R6iu7WjdIWXVv6Dy?alt=media -o train_images"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  925M  100  925M    0     0   181M      0  0:00:05  0:00:05 --:--:--  218M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5hbhyjaow9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34sbLmuW9QM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_kaggle_data():\n",
        "  os.environ['KAGGLE_USERNAME'] = \"mittalneha\"\n",
        "  os.environ['KAGGLE_KEY'] = \"59ec3f992f5fb4b510bebd8dea889381\"\n",
        "  \n",
        "  !kaggle competitions download -c aptos2019-blindness-detection\n",
        "  !kaggle datasets download -d keras/vgg16\n",
        "  \n",
        "  !mkdir kaggle-data\n",
        "  !mv sample_submission.csv kaggle-data/\n",
        "  !mv test.csv kaggle-data/\n",
        "  !mv train.csv kaggle-data/\n",
        "  !unzip test_images.zip -d kaggle-data/test_images\n",
        "  !unzip train_images.zip -d kaggle-data/train_images\n",
        "  \n",
        "  !unzip vgg16.zip -d kaggle-data/vgg16/\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZWWQIcaCUiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"kaggle-data\"\n",
        "get_kaggle_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDF4tVHX-hii",
        "colab_type": "code",
        "outputId": "aaf8f6a0-a0c0-47c3-c597-7e30b397220a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import shutil\n",
        "import imgaug as aug\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg\n",
        "import imgaug.augmenters as iaa\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fKC-e_PDaKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(os.listdir(data_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYGTQNJGBHBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(111)\n",
        "\n",
        "# Disable multi-threading in tensorflow ops\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "tf.set_random_seed(111)\n",
        "\n",
        "# Define a tensorflow session with above session configs\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "\n",
        "# Set the session in keras\n",
        "K.set_session(sess)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(111)\n",
        "\n",
        "seed = 111"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b62u52mWBPbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data_dir = Path(data_dir)\n",
        "\n",
        "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
        "train_dir = data_dir / 'train_images'\n",
        "\n",
        "# Path to validation directory\n",
        "#val_dir = data_dir / 'val'\n",
        "\n",
        "# Path to test directory\n",
        "test_dir = data_dir / 'test_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjiqiXqCFilK",
        "colab_type": "code",
        "outputId": "c4e4e766-6c1b-4b39-e92f-79261566d008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = pd.read_csv(data_dir/'train.csv')\n",
        "train.head()\n",
        "train.columns = ['id_code', 'label']\n",
        "train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id_code', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "360Ww8Hugnjp",
        "colab_type": "code",
        "outputId": "19478a29-320b-46e1-cfed-03eea8e0d37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3662, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb3hSZYyxZ8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(img):\n",
        "  \n",
        "  if img.shape[2] ==1:\n",
        "    img = np.dstack([img, img, img])\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  ret, img2 = cv2.threshold(img1, 10, 255, cv2.THRESH_BINARY)\n",
        "  points = np.argwhere(img2!=0)\n",
        "  points = np.fliplr(points)\n",
        "  x, y, w, h = cv2.boundingRect(points)\n",
        "\n",
        "#   img_cropped = img1[y:y+h, x:x+w]\n",
        "  color_cropped = img[y:y+h, x:x+w]\n",
        "\n",
        "  clahe = cv2.createCLAHE(clipLimit=4.0)\n",
        "#   img3 = clahe.apply(img_cropped)\n",
        "  lab = cv2.cvtColor(color_cropped, cv2.COLOR_BGR2LAB)\n",
        "  lab_planes = cv2.split(lab)\n",
        "  lab_planes[0] = clahe.apply(lab_planes[0])\n",
        "  lab_planes[1] = clahe.apply(lab_planes[1])\n",
        "  lab_planes[2] = clahe.apply(lab_planes[2])\n",
        "  \n",
        "\n",
        "#   plt.imshow(lab_planes[0], 'gray')\n",
        "\n",
        "  out = cv2.merge(lab_planes)\n",
        "  img3 = cv2.cvtColor(out, cv2.COLOR_LAB2BGR)\n",
        "  \n",
        "  img = cv2.resize(img3, (224,224), cv2.INTER_AREA)\n",
        "  \n",
        "#   img = img.astype(np.float32)/255\n",
        "#   img = np.expand_dims(img, axis=2)\n",
        "  \n",
        "  return img\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55l0FIHyFrLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, val = train_test_split(train_data, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbf_HjbMvtPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# valid_data = []\n",
        "# valid_labels = []\n",
        "\n",
        "# for idx, row in val.iterrows():\n",
        "#     path = str(train_dir) + '/' + row['id_code']+'.png'\n",
        "#     img = cv2.imread(path)\n",
        "#     img = preprocess_image(img)\n",
        "# #     img = img.astype(np.float32)/255.\n",
        "#     label = to_categorical(int(row['label']), num_classes=5)\n",
        "#     valid_data.append(img)\n",
        "#     valid_labels.append(label)\n",
        "    \n",
        "# valid_data = np.array(valid_data)\n",
        "# valid_labels = np.array(valid_labels)\n",
        "\n",
        "# print(\"Total number of validation examples: \", valid_data.shape)\n",
        "# print(\"Total number of labels:\", valid_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaLNbRfX7MVF",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess and keep images for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSvw2-JVfLas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_data = pd.read_csv(data_dir/'train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCUFqnFkfKes",
        "colab_type": "code",
        "outputId": "c861c716-4e5a-4444-f779-6a398c77c9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "_data['diagnosis'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5770ceb1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOv4jVxOjNGS",
        "colab_type": "code",
        "outputId": "3ba3b5ef-30d5-482a-c6a3-87b2996c8e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "count = _data['diagnosis'].value_counts()\n",
        "max_samples = count.max()\n",
        "count = count.to_dict()\n",
        "print(count)\n",
        "print(max_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 1805, 2: 999, 1: 370, 4: 295, 3: 193}\n",
            "1805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbuhlsmZsdH7",
        "colab_type": "code",
        "outputId": "2940ed25-0c33-4c37-9c80-b93b0d4fc450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "g = []\n",
        "for i in range(0,5):\n",
        "  g.append((max_samples - count[i]))\n",
        "print(g)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1435, 806, 1612, 1510]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLiIQrP1sH3g",
        "colab_type": "code",
        "outputId": "d0532ddd-9dce-421e-d269-c84802594e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gap = []\n",
        "for i in range(0,5):\n",
        "  if max_samples == count[i]:\n",
        "    gap.append(0)\n",
        "    continue\n",
        "  gap.append(np.int(np.round((max_samples - count[i])/count[i])))\n",
        "print((gap))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 4, 1, 8, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afk1C9LCygVK",
        "colab_type": "code",
        "outputId": "9a9b5c6f-4a48-4c62-e291-72ac1e1ee3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(gap)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1dLHhUzvISp",
        "colab_type": "text"
      },
      "source": [
        "**Add augmented images per images specified by this gap variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTksLOR500va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = iaa.OneOf([\n",
        "    iaa.Fliplr(1), # horizontal flips\n",
        "    iaa.Affine(rotate=20), # rotation\n",
        "    iaa.Affine(rotate=-20), # rotation\n",
        "    iaa.Affine(scale={\"x\": (1.1, 1.4), \"y\": (1.1, 1.4)})\n",
        "    ]) #random brightness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAfZm7PLhd_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = iaa.OneOf([\n",
        "    \n",
        "    iaa.Sequential([\n",
        "    iaa.Fliplr(1), # horizontal flips\n",
        "        \n",
        "    iaa.OneOf([\n",
        "    iaa.Affine(rotate=20), # rotation\n",
        "    iaa.Affine(rotate=-20), # rotation\n",
        "    iaa.Affine(scale={\"x\": (1.1, 1.4), \"y\": (1.1, 1.4)}) ])\n",
        "        \n",
        "    ]),\n",
        "    \n",
        "    iaa.Affine(rotate=20), # rotation\n",
        "    iaa.Affine(rotate=-20), # rotation\n",
        "    iaa.Affine(scale={\"x\": (1.1, 1.4), \"y\": (1.1, 1.4)}) \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZo-9zfFdxjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir kaggle-data/aug_train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjzKtZVUege7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm kaggle-data/aug_train_images/*.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oG_46i57QkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "save_images_dir = data_dir / 'aug_train_images'\n",
        "\n",
        "for idx, row in train.iterrows():\n",
        "    path = str(train_dir) + '/' + row['id_code']+'.png'\n",
        "    img = cv2.imread(path)\n",
        "    out_img = preprocess_image(img)\n",
        "\n",
        "    label = to_categorical(int(row['label']), num_classes=5)\n",
        "    \n",
        "    cv2.imwrite(str(save_images_dir)+'/'+row['id_code']+'.png', out_img)\n",
        "      \n",
        "    train_data.append(row['id_code'])\n",
        "    train_labels.append(label)\n",
        "#     train_data.append(out_img)\n",
        "#     train_labels.append(label)\n",
        "#     print(\"add {} images for class {}\".format( gap[int(row['label'])], int(row['label'])))\n",
        "    add_images = gap[np.argmax(label)]\n",
        "#     print(add_images)\n",
        "    for i in range(0, add_images):\n",
        "      aug_img = seq.augment_image(img)\n",
        "\n",
        "      aug_img = preprocess_image(aug_img)\n",
        "      \n",
        "      file_name = '{}_{}'.format(row['id_code'], i)\n",
        "#       print(str(save_images_dir)+'/'+file_name+'.png')\n",
        "      cv2.imwrite(str(save_images_dir)+'/'+file_name+'.png', aug_img)\n",
        "      \n",
        "      train_data.append(file_name)\n",
        "      train_labels.append(label)\n",
        "      \n",
        "    if len(train_labels)%100 <5:\n",
        "      print(len(train_labels))\n",
        "      \n",
        "# train_data = np.array(train_data)\n",
        "# train_labels = np.array(train_labels)\n",
        "          \n",
        "print(\"Total number of training examples: \", train_data.shape)\n",
        "print(\"Total number of labels:\", train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u47nEr-pEsFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.argmax(train_labels, axis =-1).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYCm4b2-Ez4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDucbqzeDxLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "# from itertools import izip\n",
        "\n",
        "with open('kaggle-data/aug_train.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(zip(train_data, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqSvGc3Fjt9",
        "colab_type": "code",
        "outputId": "f141419e-3467-4fda-bbf0-da1398a6503d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -l aug_train_images.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 184 Jul 29 18:54 aug_train_images.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3IGsbqmDTa6",
        "colab_type": "code",
        "outputId": "72d22850-af75-4e00-f718-b4fe13b6138b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd kaggle-data\n",
        "!zip aug_train_images.zip aug_train_images \n",
        "!cp aug_train_images.zip /content/gdrive/My\\ Drive/Colab\\ Notebooks/\n",
        "!cp aug_train.csv /content/gdrive/My\\ Drive/Colab\\ Notebooks/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kaggle-data\n",
            "  adding: aug_train_images/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ABCe2lHF4Kv",
        "colab_type": "code",
        "outputId": "a6bfe86f-12fc-46af-faf8-7fdef08f4cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_data = pd.read_csv('aug_train.csv')\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000c1434d8d7</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c1434d8d7_0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001639a390f0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001639a390f0_0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001639a390f0_1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001639a390f0_2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     000c1434d8d7  2\n",
              "0  000c1434d8d7_0  2\n",
              "1    001639a390f0  4\n",
              "2  001639a390f0_0  4\n",
              "3  001639a390f0_1  4\n",
              "4  001639a390f0_2  4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqS2-fXes5Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.columns = ['id_code', 'labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU30rIGWGclZ",
        "colab_type": "code",
        "outputId": "b556333f-3ac0-4388-91df-ce7d511e7530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "train_data['labels'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f576014c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCxjTgJmZhlzEjAzy5iTgJlZxv4/orjZuFeI78QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMv1Q3TaLfA3",
        "colab_type": "code",
        "outputId": "8b151ead-6edf-4b06-ad97-4a9f02f74b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape[0]*train_data.shape[1]*train_data.shape[2]*train_data.shape[3]*4\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4663959552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcb-0PtmLByu",
        "colab_type": "code",
        "outputId": "4933aa42-6b6f-44c2-96bb-6240f3067e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "# del train\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcPtJ91_WW6T",
        "colab_type": "code",
        "outputId": "2d4ac02e-553a-4cf1-b1bd-868c31f03e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_labels = np.argmax(train_labels, axis=-1)\n",
        "# new_labels = new_labels\n",
        "new_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7746,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dz_n009bSK5",
        "colab_type": "code",
        "outputId": "b514d79d-670e-497d-c086-87017538ee51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "a = np.histogram(new_labels)\n",
        "_ = plt.hist(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7snlp118tru",
        "colab_type": "code",
        "outputId": "3717b495-f768-4de8-a346-169e72960f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from sklearn.utils import class_weight\n",
        "# class_weight = class_weight.compute_class_weight('balanced', np.unique(orig_train_labels), orig_train_labels)\n",
        "# print(class_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.40232708 1.96962025 0.74272076 3.91446541 2.46984127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxVQh245Fs0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data = train\n",
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Rgrl9ZjO47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.data_utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayj-UW83ok23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_labels.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7U4wcEyoplS",
        "colab_type": "code",
        "outputId": "c15d25e5-9f28-44d5-84f1-2f487fda9692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[0:16].dtype\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-DGGzcKGB0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(data, labels. batch_size, mode='train'):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    steps = n//batch_size\n",
        "    \n",
        "    # Define two numpy arrays for containing batch data and labels\n",
        "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size,5), dtype=np.float32)\n",
        "\n",
        "    # Get a numpy array of all the indices of the input data\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    # Initialize a counter\n",
        "    i =0\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "        # Get the next batch \n",
        "        count = 0\n",
        "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
        "        \n",
        "        batch_data = data[]\n",
        "        batch_labels = labels[]\n",
        "        \n",
        "        yield batch_data, batch_labels\n",
        "            \n",
        "        if i>=steps:\n",
        "#             print(count)\n",
        "#             for kk in range(0,count):\n",
        "#                 plt.figure()\n",
        "#                 plt.imshow(batch_data[kk])\n",
        "#                 plt.title(str(kk))\n",
        "#             return\n",
        "            i=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XslYRaLeGGxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
        "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
        "    x = BatchNormalization(name='bn1')(x)\n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
        "    x = BatchNormalization(name='bn2')(x)\n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
        "    \n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
        "    x = BatchNormalization(name='bn3')(x)\n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
        "    x = BatchNormalization(name='bn4')(x)\n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
        "    \n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.7, name='dropout1')(x)\n",
        "    x = Dense(512, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5, name='dropout2')(x)\n",
        "    x = Dense(5, activation='softmax', name='fc3')(x)\n",
        "    \n",
        "    model = Model(inputs=input_img, outputs=x)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH4HU114GIHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  build_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0o1ZKw3GKaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Open the VGG16 weight file\n",
        "f = h5py.File('kaggle-data/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
        "\n",
        "# Select the layers for which you want to set weight.\n",
        "\n",
        "w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
        "model.layers[1].set_weights = [w,b]\n",
        "\n",
        "w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
        "model.layers[2].set_weights = [w,b]\n",
        "\n",
        "w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
        "model.layers[4].set_weights = [w,b]\n",
        "\n",
        "w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
        "model.layers[5].set_weights = [w,b]\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK_cKafJ53np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_weights('init_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyvAf3pAQpqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir kaggle-data/model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsKQsKgIetT",
        "colab_type": "code",
        "outputId": "33ad4dc3-09e5-467f-a0a4-b3e384d65be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "opt = Adam(lr=0.0001, decay=1e-5)\n",
        "es = EarlyStopping(patience=5)\n",
        "# filepath=\"kaggle-data/model/weights-improvement-{epoch:02d}.hdf5\"\n",
        "filepath=\"kaggle-data/model/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "chkpt = ModelCheckpoint(filepath=filepath, save_best_only=True, save_weights_only=True)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 07:06:28.700580 139809282156416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpFZmBTwcHz9",
        "colab_type": "text"
      },
      "source": [
        "**k-fold crossvalidation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QECy6f1bITmV",
        "colab_type": "code",
        "outputId": "5d966116-71de-4c02-e26b-1c7cc8f4bb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 16\n",
        "nb_epochs = 20\n",
        "\n",
        "# Get a train data generator\n",
        "# train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
        "train_data_gen = MY_Generator(train_data, train_labels, batch_size=batch_size)\n",
        "\n",
        "# Define the number of training steps\n",
        "nb_train_steps = train_data.shape[0]//batch_size\n",
        "\n",
        "nb_val_steps = valid_data.shape[0]//batch_size\n",
        "\n",
        "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training and validation steps: 484 and 550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSQ09bWV0n4s",
        "colab_type": "code",
        "outputId": "c2d0ade6-4843-4061-ab59-c8ed73464d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valid_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38rDDumFG8a9",
        "colab_type": "code",
        "outputId": "137db82f-139b-4618-8e19-91c1174b9635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "history = model.fit(train_data, train_labels, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=(valid_data, valid_labels), validation_steps=nb_val_steps, callbacks=[es, chkpt])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7746 samples, validate on 550 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-7ef054ebb97d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_data, train_labels, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n\u001b[0;32m----> 2\u001b[0;31m                                validation_data=(valid_data, valid_labels), validation_steps=nb_val_steps, callbacks=[es, chkpt])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[7746,3,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/Conv1_1/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/acc/Mean/_445]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[7746,3,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/Conv1_1/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJYrUvt6eYMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_model(hist):\n",
        "  \n",
        "  #Plot the curves\n",
        "  N = len(hist.history['loss'])\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), hist.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"acc\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"val_acc\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\")\n",
        "  \n",
        "  \n",
        "  #confusion matrix\n",
        "  preds = model.predict(eval_img, batch_size=16)\n",
        "  preds = np.argmax(preds, axis=-1)\n",
        "  \n",
        "  cm  = confusion_matrix(orig_eval_labels, preds)\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues, show_normed=True, show_absolute=False)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am6C4QiQWAik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_data, val_data = train_test_split(train_data, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwTP7z7VWOX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate with train data itself\n",
        "eval_img = []\n",
        "eval_labels = []\n",
        "\n",
        "for idx, row in eval_data.iterrows():\n",
        "    path = str(train_dir) + '/' + row['id_code']+'.png'\n",
        "    img = cv2.imread(path)\n",
        "    img = preprocess_image(img)\n",
        "    label = to_categorical(int(row['label']), num_classes=5)\n",
        "    eval_img.append(img)\n",
        "    eval_labels.append(label)\n",
        "    \n",
        "eval_img = np.array(eval_img)\n",
        "eval_labels = np.array(eval_labels)\n",
        "\n",
        "# Original labels\n",
        "orig_eval_labels = np.argmax(eval_labels, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GURph7mIGhlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.utils import class_weight\n",
        "# class_weight = class_weight.compute_class_weight('balanced', np.unique(orig_train_labels), orig_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUG2nSKT8Udy",
        "colab_type": "code",
        "outputId": "febd61e2-38dc-4470-dbde-6b2478c985a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# kappa_metrics = Metrics()\n",
        "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-6:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 559, in _run\n",
            "    sequence = list(range(len(self.sequence)))\n",
            "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-1caa41959e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n\u001b[0;32m----> 2\u001b[0;31m                                validation_data=(valid_data, valid_labels),callbacks=[es, chkpt])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEa0u5kbpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3gIa3p7GNfE",
        "colab_type": "code",
        "outputId": "855357fc-81e5-455f-8c36-01aa8e6557bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt],\n",
        "                              class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n",
        "\n",
        "check_model(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - 918s 4s/step - loss: 1.8907 - acc: 0.2253 - val_loss: 1.8837 - val_acc: 0.2997\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - 906s 4s/step - loss: 1.9178 - acc: 0.1811 - val_loss: 1.9246 - val_acc: 0.0654\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - 909s 4s/step - loss: 1.8913 - acc: 0.1433 - val_loss: 1.9388 - val_acc: 0.0845\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - 926s 5s/step - loss: 1.9083 - acc: 0.1305 - val_loss: 1.9512 - val_acc: 0.0654\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - 933s 5s/step - loss: 1.8823 - acc: 0.1226 - val_loss: 1.9544 - val_acc: 0.0763\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - 933s 5s/step - loss: 1.8293 - acc: 0.1201 - val_loss: 1.9407 - val_acc: 0.0654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-eadb2a92eab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                               class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-dc59c7af41bb>\u001b[0m in \u001b[0;36mcheck_model\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m#confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_img' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEaCAYAAADpMdsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0dg8iIhINDYPIiISjc2DiIhE+w8MfBYlZ+JSLwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC2zBuEnILuD",
        "colab_type": "code",
        "outputId": "4e89ac94-b838-4ff4-c69e-2a27a63f6b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt], initial_epoch=len(history.history['loss']),\n",
        "                              class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n",
        "\n",
        "check_model(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/20\n",
            "205/205 [==============================] - 911s 4s/step - loss: 1.8651 - acc: 0.1405 - val_loss: 1.9351 - val_acc: 0.0654\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - 915s 4s/step - loss: 1.8507 - acc: 0.1189 - val_loss: 1.9276 - val_acc: 0.0654\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - 907s 4s/step - loss: 1.8965 - acc: 0.1043 - val_loss: 1.9348 - val_acc: 0.0654\n",
            "Epoch 10/20\n",
            "176/205 [========================>.....] - ETA: 2:13 - loss: 1.7917 - acc: 0.1286"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5bf90bbc926f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n\u001b[1;32m      2\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchkpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                               class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9GFZcY1GwCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_model(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQJk_BgVzajr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt], initial_epoch=len(history.history['loss'],\n",
        "                              class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n",
        "\n",
        "check_model(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cJYR_bsm-hx",
        "colab_type": "text"
      },
      "source": [
        "**k-fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB714TT925YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoLBXbGp-mxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHDYd4XlcHbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "batch_size = 16\n",
        "nb_epochs = 20\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "# kappa_metrics = Metrics()\n",
        "i = 0\n",
        "init_epoch = 0\n",
        "\n",
        "for train_idx, val_idx in kfold.split(train_data, Y):\n",
        "  print(train_idx)\n",
        "  train_data_gen = data_gen(data=train_data.iloc[train_idx], batch_size=batch_size)\n",
        "  val_data_gen = data_gen(data=train_data.iloc[val_idx], batch_size=batch_size, mode='validation')\n",
        "  \n",
        "  nb_train_steps = len(train_data.iloc[train_idx]) //batch_size\n",
        "  nb_val_steps = len(train_data.iloc[val_idx]) //batch_size\n",
        "  \n",
        "#   model =  build_model()\n",
        "  model.load_weights('init_weights.h5')\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)\n",
        "  \n",
        "  r = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                               validation_data=val_data_gen,\n",
        "                                validation_steps=nb_val_steps, callbacks=[es, chkpt], \n",
        "                                class_weight={0:0.4040466, 1:1.9439528, 2:0.74128234, 3:3.89940828, 4:2.46816479})\n",
        "  kfold_history.append(r)\n",
        "#   del model\n",
        "  gc.collect()\n",
        "#   init_epoch += len(history.history['loss'])\n",
        "#   print(\"init_epoch = {}\".format(init_epoch))\n",
        "  i+=1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvFwi4_w8w5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold_history.update(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWHAxWRM82vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSfTbRPfoVTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history['acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJsUqS3LvR2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def histogram(ratings, min_rating=None, max_rating=None):\n",
        "    \"\"\"\n",
        "    Returns the counts of each type of rating that a rater made\n",
        "    \"\"\"\n",
        "    if min_rating is None:\n",
        "        min_rating = min(ratings)\n",
        "    if max_rating is None:\n",
        "        max_rating = max(ratings)\n",
        "    num_ratings = int(max_rating - min_rating + 1)\n",
        "    hist_ratings = [0 for x in range(num_ratings)]\n",
        "    for r in ratings:\n",
        "        hist_ratings[r - min_rating] += 1\n",
        "    return hist_ratings\n",
        "  \n",
        "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
        "    \"\"\"\n",
        "    Calculates the quadratic weighted kappa\n",
        "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
        "    value, which is a measure of inter-rater agreement between two raters\n",
        "    that provide discrete numeric ratings.  Potential values range from -1\n",
        "    (representing complete disagreement) to 1 (representing complete\n",
        "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
        "    chance.\n",
        "\n",
        "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
        "    each correspond to a list of integer ratings.  These lists must have the\n",
        "    same length.\n",
        "\n",
        "    The ratings should be integers, and it is assumed that they contain\n",
        "    the complete range of possible ratings.\n",
        "\n",
        "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
        "    is the minimum possible rating, and max_rating is the maximum possible\n",
        "    rating\n",
        "    \"\"\"\n",
        "    rater_a = np.array(rater_a, dtype=int)\n",
        "    rater_b = np.array(rater_b, dtype=int)\n",
        "    assert(len(rater_a) == len(rater_b))\n",
        "    if min_rating is None:\n",
        "        min_rating = min(min(rater_a), min(rater_b))\n",
        "    if max_rating is None:\n",
        "        max_rating = max(max(rater_a), max(rater_b))\n",
        "    print(min_rating.shape)\n",
        "    print(max_rating.shape)\n",
        "    conf_mat = confusion_matrix(rater_a, rater_b)\n",
        "    num_ratings = len(conf_mat)\n",
        "    num_scored_items = float(len(rater_a))\n",
        "\n",
        "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
        "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
        "\n",
        "    numerator = 0.0\n",
        "    denominator = 0.0\n",
        "\n",
        "    for i in range(num_ratings):\n",
        "        for j in range(num_ratings):\n",
        "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
        "                              / num_scored_items)\n",
        "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
        "            numerator += d * conf_mat[i][j] / num_scored_items\n",
        "            denominator += d * expected_count / num_scored_items\n",
        "\n",
        "    return 1.0 - numerator / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBWXEqpvVAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_kappas = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        X_val, y_val = self.validation_data[:2]\n",
        "        y_val = np.argmax(y_val, axis=-1)\n",
        "#         y_val = y_val.astype(int).sum(axis=1) - 1\n",
        "        print(y_val.shape)\n",
        "        \n",
        "        y_pred = self.model.predict(X_val)\n",
        "        y_pred = np.argmax(y_pred, axis=-1)\n",
        "        print(y_pred.shape)\n",
        "#         print(y_pred[0])\n",
        "#         y_pred = y_pred.astype(int).sum(axis=1) - 1\n",
        "        \n",
        "#         print(y_pred.shape)\n",
        "        _val_kappa = quadratic_weighted_kappa(y_val, y_pred)\n",
        "\n",
        "#         _val_kappa = cohen_kappa_score(\n",
        "#             y_val,\n",
        "#             y_pred, \n",
        "#             weights='quadratic'\n",
        "#         )\n",
        "\n",
        "        self.val_kappas.append(_val_kappa)\n",
        "\n",
        "        print(f\"val_kappa: {_val_kappa:.4f}\")\n",
        "        \n",
        "        if _val_kappa == max(self.val_kappas):\n",
        "            print(\"Validation Kappa has improved. Saving model.\")\n",
        "            self.model.save('kaggle-data/model/model.h5')\n",
        "\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}