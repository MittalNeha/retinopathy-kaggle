{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception-basemodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MittalNeha/retinopathy-kaggle/blob/master/Xception_basemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMNM_ZaOgwPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import shutil\n",
        "import imgaug as aug\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg\n",
        "import imgaug.augmenters as iaa\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import (Activation, Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D,\n",
        "                          Dense, BatchNormalization, GlobalAveragePooling2D)\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "\n",
        "from keras.applications.xception import Xception\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras import metrics\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jzw7yIaiaLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qMSo-bFuWsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"mittalneha\"\n",
        "os.environ['KAGGLE_KEY'] = \"59ec3f992f5fb4b510bebd8dea889381\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao3wR7Axiaq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_kaggle_data():\n",
        "  os.environ['KAGGLE_USERNAME'] = \"mittalneha\"\n",
        "  os.environ['KAGGLE_KEY'] = \"59ec3f992f5fb4b510bebd8dea889381\"\n",
        "  \n",
        "  !kaggle competitions download -c aptos2019-blindness-detection\n",
        "#   !kaggle datasets download -d keras/resnet50\n",
        "  !kaggle datasets download -d keras/xception\n",
        "  \n",
        "  !mkdir kaggle-data\n",
        "  !mv sample_submission.csv kaggle-data/\n",
        "  !mv test.csv kaggle-data/\n",
        "  !mv train.csv kaggle-data/\n",
        "  !unzip test_images.zip -d kaggle-data/test_images\n",
        "#   !unzip train_images.zip -d kaggle-data/train_images\n",
        "  !cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/aug_train_images.zip .\n",
        "  !cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/aug_train.csv .\n",
        "  \n",
        "  !unzip aug_train_images.zip\n",
        "  !mv aug_train_images kaggle-data/\n",
        "  !mv aug_train.csv kaggle-data/\n",
        "  \n",
        "  \n",
        "  !unzip xception.zip -d kaggle-data/xception/\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "migL32nXiel8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"kaggle-data\"\n",
        "# get_kaggle_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJlLRV1aiiv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORKERS = 2\n",
        "CHANNEL = 3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SIZE = 300\n",
        "NUM_CLASSES = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm4lMspKiqkU",
        "colab_type": "code",
        "outputId": "fce1bae5-203c-4ec8-8bd3-c90cc4f51fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "df_train = pd.read_csv('kaggle-data/aug_train.csv')\n",
        "df_test = pd.read_csv('kaggle-data/test.csv')\n",
        "\n",
        "df_train.columns = ['id_code', 'diagnosis']\n",
        "\n",
        "x = df_train['id_code']\n",
        "y = df_train['diagnosis']\n",
        "\n",
        "x, y = shuffle(x, y, random_state=8)\n",
        "y.hist()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff98c9427f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCxjTgJmZhlzEjAzy5iTgJlZxv4/orjZuFeI78QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K22T2Aiiv4l",
        "colab_type": "code",
        "outputId": "b036d6aa-3531-4720-aaf3-aed39f52a87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
        "                                                      stratify=y, random_state=8)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7785,)\n",
            "(7785, 5)\n",
            "(1374,)\n",
            "(1374, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24XlFfhmi7Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_Generator(Sequence):\n",
        "\n",
        "    def __init__(self, image_filenames, labels,\n",
        "                 batch_size, is_train=True,\n",
        "                 mix=False, augment=False):\n",
        "        self.image_filenames, self.labels = image_filenames, labels\n",
        "        self.batch_size = batch_size\n",
        "        self.is_train = is_train\n",
        "        self.is_augment = augment\n",
        "        if(self.is_train):\n",
        "            self.on_epoch_end()\n",
        "        self.is_mix = mix\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        if(self.is_train):\n",
        "            return self.train_generate(batch_x, batch_y)\n",
        "        return self.valid_generate(batch_x, batch_y)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if(self.is_train):\n",
        "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    def mix_up(self, x, y):\n",
        "        lam = np.random.beta(0.2, 0.4)\n",
        "        ori_index = np.arange(int(len(x)))\n",
        "        index_array = np.arange(int(len(x)))\n",
        "        np.random.shuffle(index_array)        \n",
        "        \n",
        "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
        "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
        "        \n",
        "        return mixed_x, mixed_y\n",
        "\n",
        "    def train_generate(self, batch_x, batch_y):\n",
        "        batch_images = []\n",
        "        for (sample, label) in zip(batch_x, batch_y):\n",
        "            img = cv2.imread('kaggle-data/aug_train_images/'+sample+'.png')\n",
        "            img = cv2.resize(img, (SIZE, SIZE))\n",
        "#             if(self.is_augment):\n",
        "#                 img = seq.augment_image(img)\n",
        "            batch_images.append(img)\n",
        "        batch_images = np.array(batch_images, np.float32) / 255\n",
        "        batch_y = np.array(batch_y, np.float32)\n",
        "        if(self.is_mix):\n",
        "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
        "        return batch_images, batch_y\n",
        "\n",
        "    def valid_generate(self, batch_x, batch_y):\n",
        "        batch_images = []\n",
        "        for (sample, label) in zip(batch_x, batch_y):\n",
        "            img = cv2.imread('kaggle-data/aug_train_images/'+sample+'.png')\n",
        "            img = cv2.resize(img, (SIZE, SIZE))\n",
        "            batch_images.append(img)\n",
        "        batch_images = np.array(batch_images, np.float32) / 255\n",
        "        batch_y = np.array(batch_y, np.float32)\n",
        "        return batch_images, batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmEdbXXQkyKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, n_out):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    base_model = Xception(include_top=False,\n",
        "                   weights=None,\n",
        "                   input_tensor=input_tensor)\n",
        "    base_model.load_weights('kaggle-data/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
        "    model = Model(input_tensor, final_output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPw_sCSe2A0v",
        "colab_type": "code",
        "outputId": "0fe42d51-e47e-4cac-cf70-1cef58c98a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir 'kaggle-data/model'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘kaggle-data/model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvA3rgEzk1PN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "a14a0eb4-de86-4bca-9f54-0febfc54052f"
      },
      "source": [
        "# create callbacks list\n",
        "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
        "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
        "\n",
        "epochs = 30; batch_size = 16\n",
        "checkpoint = ModelCheckpoint('kaggle-data/model/xception-{epoch:02d}-{val_acc:.2f}.h5', monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True, mode='min', save_weights_only = True)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
        "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=9)\n",
        "\n",
        "csv_logger = CSVLogger(filename='kaggle-data/model/training_log.csv',\n",
        "                       separator=',',\n",
        "                       append=True)\n",
        "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
        "\n",
        "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
        "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
        "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
        "\n",
        "model = create_model(\n",
        "    input_shape=(SIZE,SIZE,3), \n",
        "    n_out=NUM_CLASSES)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 09:53:10.809938 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0802 09:53:10.854458 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0802 09:53:10.870653 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0802 09:53:10.917546 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0802 09:53:10.923302 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0802 09:53:15.009035 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0802 09:53:16.093259 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0802 09:53:27.576924 140711461771136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzdycCKk5f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reference link: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow\n",
        "def kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=5, bsize=32, name='kappa'):\n",
        "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
        "        Args:\n",
        "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
        "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
        "            y_pow: int,  e.g. y_pow=2\n",
        "            N: typically num_classes of the model\n",
        "            bsize: batch_size of the training or validation ops\n",
        "            eps: a float, prevents divide by zero\n",
        "            name: Optional scope/name for op_scope.\n",
        "        Returns:\n",
        "            A tensor with the kappa loss.\"\"\"\n",
        "\n",
        "    with tf.name_scope(name):\n",
        "        y_true = tf.to_float(y_true)\n",
        "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
        "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
        "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
        "    \n",
        "        pred_ = y_pred ** y_pow\n",
        "        try:\n",
        "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
        "        except Exception:\n",
        "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
        "    \n",
        "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
        "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
        "    \n",
        "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
        "    \n",
        "        nom = tf.reduce_sum(weights * conf_mat)\n",
        "        denom = tf.reduce_sum(weights * tf.matmul(\n",
        "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
        "                              tf.to_float(bsize))\n",
        "    \n",
        "        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAAUbglclAkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "class QWKEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.batch_size = batch_size\n",
        "        self.valid_generator, self.y_val = validation_data\n",
        "        self.history = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
        "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
        "                                                  workers=1, use_multiprocessing=False,\n",
        "                                                  verbose=1)\n",
        "            def flatten(y):\n",
        "                return np.argmax(y, axis=1).reshape(-1)\n",
        "            \n",
        "            score = cohen_kappa_score(flatten(self.y_val),\n",
        "                                      flatten(y_pred),\n",
        "                                      labels=[0,1,2,3,4],\n",
        "                                      weights='quadratic')\n",
        "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
        "            self.history.append(score)\n",
        "            if score >= max(self.history):\n",
        "                print('saving checkpoint: ', score)\n",
        "                self.model.save('kaggle-data/model/xception_bestqwk-{epoch:02d}-{val_acc:.2f}.h5')\n",
        "\n",
        "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
        "                    batch_size=batch_size, interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5da7rwx4weq",
        "colab_type": "code",
        "outputId": "155648b4-1e70-4257-9be7-0d7125083732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7785, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD-AovJglBXF",
        "colab_type": "code",
        "outputId": "3f661bf8-a680-40f1-b668-690474394087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# warm up model\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for i in range(-3,0):\n",
        "    model.layers[i].trainable = True\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(1e-3))\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
        "    epochs=2,\n",
        "    workers=WORKERS, use_multiprocessing=True,\n",
        "    verbose=1,\n",
        "    callbacks=[qwk])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 09:53:28.275720 140711461771136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0802 09:53:28.451393 140711461771136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cf53e1d82b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     callbacks=[qwk])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node block1_conv2_bn/FusedBatchNorm}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_1799]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node block1_conv2_bn/FusedBatchNorm}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuXpIgx0lEQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train all layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\n",
        "model.compile(\n",
        "    #loss='categorical_crossentropy',\n",
        "             loss=kappa_loss,\n",
        "            optimizer=Adam(lr=1e-4))\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_mixup,\n",
        "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    workers=1, use_multiprocessing=False,\n",
        "    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q0hKyfFlOv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_model(hist):\n",
        "  \n",
        "  #Plot the curves\n",
        "  N = len(hist.history['loss'])\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, N), hist.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"acc\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, N), hist.history[\"val_acc\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\")\n",
        "  \n",
        "  \n",
        "  #confusion matrix\n",
        "  preds = []\n",
        "  for i, name in tqdm(enumerate(valid_x)):\n",
        "      path = os.path.join('kaggle-data/aug_train_images/', name+'.png')\n",
        "      image = cv2.imread(path)\n",
        "  #     print(str(path))\n",
        "      image = cv2.resize(image, (SIZE, SIZE))\n",
        "      score_predict = model.predict((image[np.newaxis])/255)\n",
        "      label_predict = np.argmax(score_predict)\n",
        "      preds.append(label_predict)\n",
        "\n",
        "  valid_labels = np.argmax(valid_y, axis=-1)\n",
        "  \n",
        "  cm  = confusion_matrix(valid_labels, preds)\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues, show_normed=True, show_absolute=False)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo48G_dEoSyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_model(history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}